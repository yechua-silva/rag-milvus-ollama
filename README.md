# ü§ñ Sistema RAG con Arquitectura Limpia, Milvus y Aceleraci√≥n por GPU

Este es un sistema de chat inteligente y escalable que permite hacer preguntas sobre documentos PDF. Utiliza el patr√≥n de **Arquitectura Limpia** para un dise√±o modular y soporta **aceleraci√≥n por GPU** para optimizar el rendimiento del proceso de ingesta de datos.

---

## ‚ú® Caracter√≠sticas Principales

- ‚úÖ **Procesamiento de Documentos Flexible**: Extracci√≥n de texto de m√∫ltiples archivos PDF en una carpeta dedicada.
- ‚úÖ **Chunking Adaptativo**: Divisi√≥n inteligente del texto que preserva el contexto estructural del documento.
- ‚úÖ **Base de Datos Vectorial Robusta**: Almacenamiento y b√∫squeda eficiente de embeddings con **Milvus**.
- ‚úÖ **Procesamiento Paralelo de Embeddings**: Generaci√≥n de embeddings de forma acelerada usando la **GPU** (v√≠a ONNX Runtime + DirectML/CUDA) o recurriendo a la **CPU** con **Ollama**.
- ‚úÖ **Arquitectura Limpia**: Dise√±o modular y escalable siguiendo principios de la Programaci√≥n Orientada a Objetos (POO), ideal para proyectos de nivel profesional.
- ‚úÖ **Chat Interactivo**: Interfaz de l√≠nea de comandos para consultas en lenguaje natural sobre el contenido de los documentos.

---

## üöÄ Instalaci√≥n R√°pida

### Prerrequisitos

- **Python 3.8+**
- **Docker** y **Docker Compose** (necesarios para Milvus)
- **Git**

### 1. Clonar el repositorio

````bash
git clone [https://github.com/tu-usuario/rag-milvus-ollama.git](https://github.com/tu-usuario/rag-milvus-ollama.git)
cd rag-milvus-ollama
### 2. Crear entorno virtual

```bash
# Windows
python -m venv venv
venv\Scripts\activate

# Linux/macOS
python3 -m venv venv
source venv/bin/activate
````

### 3. Instalar dependencias

```bash
pip install -r requirements.txt
```

### 4. Instalar Ollama

#### Windows

1. Descargar desde [ollama.ai](https://ollama.ai/download)
2. Ejecutar el instalador
3. Verificar instalaci√≥n: `ollama --version`

#### Linux

```bash
curl -fsSL https://ollama.ai/install.sh | sh
```

#### macOS

```bash
brew install ollama
```

### 5. Descargar modelos necesarios

```bash
# Modelo de embeddings (requerido)
ollama pull mxbai-embed-large

# Modelo de lenguaje para chat (requerido)
ollama pull qwen2.5:3b

# Modelos alternativos (opcional)
ollama pull llama3.1:8b
ollama pull nomic-embed-text
```

### 6. Iniciar Milvus

```bash
docker-compose up -d
```

Verificar que Milvus est√© funcionando:

```bash
curl http://localhost:19530/health
```

## üìñ Uso

### Configuraci√≥n

Modifica el archivo `.env` (opcional) o modifica `config.py`:

**Configuracion de Acelarion (GPU/CPU)**
El sistema est√° dise√±ado para detectar y usar autom√°ticamente tu GPU.

- Para tarjetas AMD (DirectML) / NVIDIA (CUDA): El sistema intentar√° usar la GPU por defecto. Aseg√∫rate de tener los drivers m√°s recientes instalados.

- Para forzar el uso de la CPU: En config.py, cambia la siguiente l√≠nea:

```py
USE_GPU = os.environ.get("USE_GPU", "false").lower() == "true"
```

```env
# Rutas (usar DOCS_FOLDER para m√∫ltiples archivos)
DOCS_FOLDER=./docs

# Milvus
MILVUS_URI=http://127.0.0.1:19530
COLLECTION_NAME=knowledge_base

# Modelos
EMBEDDING_MODEL=mxbai-embed-large
LLM_MODEL=qwen2.5:3b

# Procesamiento de texto
CHUNK_SIZE=800
CHUNK_OVERLAP=100
SEARCH_TOP_K=5
```

### Ingesta de documentos

Coloca tu archivo PDF en el directorio del proyecto y ejecuta:

```bash
python main.py --ingest
```

### Iniciar chat interactivo

```bash
python main.py
```

### Ejemplo de uso

```
Sistema de Chat RAG listo. Escribe 'salir' para terminar.

Pregunta: ¬øQui√©n es el autor del libro y de qu√© se trata la l√≥gica de programaci√≥n?

Respuesta:
El autor del libro "L√≥gica de Programaci√≥n" es Omar Iv√°n Trejos Buritic√°. La l√≥gica de programaci√≥n es la uni√≥n de conceptos sencillos para el dise√±o de soluciones l√≥gicas, que nos permiten dise√±ar soluciones a problemas que pueden ser implementados a trav√©s de un computador. Se basa en un conjunto de normas t√©cnicas que permiten desarrollar un algoritmo entendible para la soluci√≥n de un problema.
```

## üõ†Ô∏è Desarrollo

### Estructura del proyecto

```
/tu_proyecto
|-- src/
|   |-- domain/                         # Modelos de datos puros (e.g., DocumentChunk)
|   |-- application/                    # L√≥gica de negocio y orquestaci√≥n
|   |   |-- chat_service.py
|   |   ‚îú‚îÄ‚îÄ ingestion_orchestrator.py   # Orquestador para ingesta paralela con GPU
|   |   ‚îú‚îÄ‚îÄ orchestrator.py             # Orquestador general (ingesta/chat)
|   |   ‚îî‚îÄ‚îÄ interfaces.py               # Definici√≥n de interfaces (contratos)
|   ‚îú‚îÄ‚îÄ infrastructure/                 # Implementaciones concretas y dependencias
|   ‚îÇ   ‚îú‚îÄ‚îÄ document_loader.py          # Carga de PDFs
|   ‚îÇ   ‚îú‚îÄ‚îÄ embedding_gpu.py            # Generador de embeddings con GPU (ONNX)
|   ‚îÇ   ‚îú‚îÄ‚îÄ embedding_manager.py        # Generador de embeddings con CPU (Ollama)
|   ‚îÇ   ‚îú‚îÄ‚îÄ text_processor.py           # L√≥gica de chunking y limpieza de texto
|   ‚îÇ   ‚îî‚îÄ‚îÄ vector_store_manager.py     # L√≥gica de Milvus
|   ‚îî‚îÄ‚îÄ main.py                         # Punto de entrada y configuraci√≥n
‚îú‚îÄ‚îÄ docs/                               # Carpeta para documentos PDF
‚îú‚îÄ‚îÄ models/                             # Modelos ONNX generados autom√°ticamente
‚îú‚îÄ‚îÄ config.py                           # Configuraci√≥n centralizada
‚îú‚îÄ‚îÄ docker-compose.yml                  # Configuraci√≥n de Docker para Milvus
‚îî‚îÄ‚îÄ requirements.txt                    # Dependencias del proyecto
```

### Arquitectura Clean

El proyecto sigue principios de **Clean Architecture**:

- **Infrastructure**: Adaptadores externos (Milvus, Ollama, archivos)
- **Application**: Casos de uso y l√≥gica de negocio
- **Domain**: Modelos y entidades (models.py)

### A√±adir nuevos tipos de documentos

Para soportar otros formatos:

1. Crear nuevo loader en `infrastructure/`
2. Implementar interfaz similar a `PdfDocumentLoader`
3. Registrar en `main.py`

## üìä Monitoreo

### Ver estad√≠sticas de Milvus

```python
from src.infrastructure.vector_store_manager import MilvusManager

vector_store = MilvusManager("http://localhost:19530", "collection_name", 1024)
stats = vector_store.get_stats()
print(stats)
```

### Interfaz web de Milvus

Accede a `http://localhost:9001` (MinIO) para gesti√≥n de archivos.

## üîß Soluci√≥n de Problemas

### Error: "GPU no detectada" o DmlExecutionProvider not found

**Causa Principal:** onnxruntime no puede comunicarse con tu GPU.

**Soluci√≥n:**

1. Actualiza los drivers de tu GPU a la √∫ltima versi√≥n disponible (Adrenalin para AMD, Game Ready/Studio para NVIDIA).

2. Realiza una reinstalaci√≥n limpia de las librer√≠as de ONNX:

```bash
pip uninstall onnx onnxruntime onnxruntime-directml -y
pip install onnx onnxruntime-directml
```

### Error: "Ollama not found"

```bash
# Verificar instalaci√≥n
ollama --version

# Iniciar servicio (Linux/macOS)
sudo systemctl start ollama
```

### Error: "Connection refused" (Milvus)

```bash
# Verificar contenedores
docker-compose ps

# Reiniciar servicios
docker-compose down && docker-compose up -d
```

### Error: "Modelo no encontrado"

```bash
# Listar modelos instalados
ollama list

# Instalar modelo faltante
ollama pull mxbai-embed-large
```

### Error: "No se encontraron archivos PDF"

Asegurate de que la carpeta `docs` exista y contenga archivos PDF:

```bash
mkdir docs
```

##

## üöÄ Mejoras Futuras

- [ ] Implementar un HierarchicalChunker m√°s avanzado.

- [ ] Incorporar un Reranker para mejorar la precisi√≥n de las respuestas.

- [ ] Soportar m√∫ltiples tipos de documentos (HTML, Word, etc.).

- [ ] A√±adir una interfaz web con Streamlit o Gradio.

- [ ] Desarrollar una API REST con FastAPI.

- [ ] Integrar m√©tricas de evaluaci√≥n de relevancia.

- [ ] Desarrollar un sistema de memoria de conversaci√≥n.

## üìÑ Licencia

Este proyecto est√° bajo la Licencia MIT. Ver `LICENSE` para m√°s detalles.

## üôè Agradecimientos

- [Milvus](https://milvus.io/) - Base de datos vectorial
- [Ollama](https://ollama.ai/) - Modelos LLM locales
- [PyMuPDF](https://pymupdf.readthedocs.io/) - Procesamiento de PDFs

## üìû Contacto

**[Yechua Silva]** - [yechua_silva@outlook.cl]

**[Yechua Linkedin]** - [[Linkedin](https://www.linkedin.com/in/yechua-silva/)]

Proyecto: [Github Rag Milvus Ollama](https://github.com/yechua-silva/rag-milvus-ollama)

---

‚≠ê Si este proyecto te resulta √∫til, ¬°considera darle una estrella!
